{
  "model_path": "models/mistral-7b-merged",
  "generation": {
    "min_words": 2300,
    "max_words": 2700,
    "temperature": 0.8,
    "top_p": 0.95,
    "top_k": 50,
    "repetition_penalty": 1.15,
    "no_repeat_ngram_size": 3,
    "length_penalty": 1.0,
    "complete_sentences": true,
    "early_stopping": true
  },
  "environment": {
    "hf_home": "E:/huggingface_cache",
    "transformers_cache": "E:/huggingface_cache/transformers"
  }
}